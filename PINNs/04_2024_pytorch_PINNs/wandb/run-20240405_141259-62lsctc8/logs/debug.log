2024-04-05 14:12:59,201 INFO    MainThread:20936 [wandb_setup.py:_flush():76] Current SDK version is 0.16.6
2024-04-05 14:12:59,201 INFO    MainThread:20936 [wandb_setup.py:_flush():76] Configure stats pid to 20936
2024-04-05 14:12:59,202 INFO    MainThread:20936 [wandb_setup.py:_flush():76] Loading settings from C:\Users\Ian_b\.config\wandb\settings
2024-04-05 14:12:59,202 INFO    MainThread:20936 [wandb_setup.py:_flush():76] Loading settings from C:\Users\Ian_b\Documents\GitHub\PatternLearning\PINNs\Pytorch_implementation\wandb\settings
2024-04-05 14:12:59,202 INFO    MainThread:20936 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-04-05 14:12:59,202 INFO    MainThread:20936 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-04-05 14:12:59,202 INFO    MainThread:20936 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'cooling_eqn.py', 'program_abspath': 'C:\\Users\\Ian_b\\Documents\\GitHub\\PatternLearning\\PINNs\\Pytorch_implementation\\cooling_eqn.py', 'program': 'C:\\Users\\Ian_b\\Documents\\GitHub\\PatternLearning\\PINNs\\Pytorch_implementation\\cooling_eqn.py'}
2024-04-05 14:12:59,202 INFO    MainThread:20936 [wandb_setup.py:_flush():76] Applying login settings: {}
2024-04-05 14:12:59,202 INFO    MainThread:20936 [wandb_setup.py:_flush():76] Applying login settings: {'api_key': '***REDACTED***'}
2024-04-05 14:12:59,202 INFO    MainThread:20936 [wandb_init.py:_log_setup():521] Logging user logs to C:\Users\Ian_b\Documents\GitHub\PatternLearning\PINNs\Pytorch_implementation\wandb\run-20240405_141259-62lsctc8\logs\debug.log
2024-04-05 14:12:59,202 INFO    MainThread:20936 [wandb_init.py:_log_setup():522] Logging internal logs to C:\Users\Ian_b\Documents\GitHub\PatternLearning\PINNs\Pytorch_implementation\wandb\run-20240405_141259-62lsctc8\logs\debug-internal.log
2024-04-05 14:12:59,202 INFO    MainThread:20936 [wandb_init.py:init():561] calling init triggers
2024-04-05 14:12:59,202 INFO    MainThread:20936 [wandb_init.py:init():568] wandb.init called with sweep_config: {}
config: {'_name': 'wandb.config', '__doc__': 'Config object.\n\n    Config objects are intended to hold all of the hyperparameters associated with\n    a wandb run and are saved with the run object when `wandb.init` is called.\n\n    We recommend setting `wandb.config` once at the top of your training experiment or\n    setting the config as a parameter to init, ie. `wandb.init(config=my_config_dict)`\n\n    You can create a file called `config-defaults.yaml`, and it will automatically be\n    loaded into `wandb.config`. See https://docs.wandb.com/guides/track/config#file-based-configs.\n\n    You can also load a config YAML file with your custom name and pass the filename\n    into `wandb.init(config="special_config.yaml")`.\n    See https://docs.wandb.com/guides/track/config#file-based-configs.\n\n    Examples:\n        Basic usage\n        ```\n        wandb.config.epochs = 4\n        wandb.init()\n        for x in range(wandb.config.epochs):\n            # train\n        ```\n\n        Using wandb.init to set config\n        ```\n        wandb.init(config={"epochs": 4, "batch_size": 32})\n        for x in range(wandb.config.epochs):\n            # train\n        ```\n\n        Nested configs\n        ```\n        wandb.config[\'train\'][\'epochs\'] = 4\n        wandb.init()\n        for x in range(wandb.config[\'train\'][\'epochs\']):\n            # train\n        ```\n\n        Using absl flags\n        ```\n        flags.DEFINE_string(‘model’, None, ‘model to run’) # name, default, help\n        wandb.config.update(flags.FLAGS) # adds all absl flags to config\n        ```\n\n        Argparse flags\n        ```python\n        wandb.init()\n        wandb.config.epochs = 4\n\n        parser = argparse.ArgumentParser()\n        parser.add_argument(\n            "-b",\n            "--batch-size",\n            type=int,\n            default=8,\n            metavar="N",\n            help="input batch size for training (default: 8)",\n        )\n        args = parser.parse_args()\n        wandb.config.update(args)\n        ```\n\n        Using TensorFlow flags (deprecated in tensorflow v2)\n        ```python\n        flags = tf.app.flags\n        flags.DEFINE_string("data_dir", "/tmp/data")\n        flags.DEFINE_integer("batch_size", 128, "Batch size.")\n        wandb.config.update(flags.FLAGS)  # adds all of the tensorflow flags to config\n        ```\n    '}
2024-04-05 14:12:59,203 INFO    MainThread:20936 [wandb_init.py:init():611] starting backend
2024-04-05 14:12:59,203 INFO    MainThread:20936 [wandb_init.py:init():615] setting up manager
2024-04-05 14:12:59,207 INFO    MainThread:20936 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=spawn, using: spawn
2024-04-05 14:12:59,209 INFO    MainThread:20936 [wandb_init.py:init():623] backend started and connected
2024-04-05 14:12:59,217 INFO    MainThread:20936 [wandb_init.py:init():715] updated telemetry
2024-04-05 14:12:59,218 INFO    MainThread:20936 [wandb_init.py:init():748] communicating run to backend with 90.0 second timeout
2024-04-05 14:12:59,806 INFO    MainThread:20936 [wandb_run.py:_on_init():2357] communicating current version
2024-04-05 14:13:00,124 INFO    MainThread:20936 [wandb_run.py:_on_init():2366] got version response 
2024-04-05 14:13:00,125 INFO    MainThread:20936 [wandb_init.py:init():799] starting run threads in backend
2024-04-05 14:13:00,257 INFO    MainThread:20936 [wandb_run.py:_console_start():2335] atexit reg
2024-04-05 14:13:00,257 INFO    MainThread:20936 [wandb_run.py:_redirect():2190] redirect: wrap_raw
2024-04-05 14:13:00,257 INFO    MainThread:20936 [wandb_run.py:_redirect():2255] Wrapping output streams.
2024-04-05 14:13:00,257 INFO    MainThread:20936 [wandb_run.py:_redirect():2280] Redirects installed.
2024-04-05 14:13:00,258 INFO    MainThread:20936 [wandb_init.py:init():842] run started, returning control to user process
2024-04-05 14:13:06,829 WARNING MsgRouterThr:20936 [router.py:message_loop():77] message_loop has been closed
